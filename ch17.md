## Seeing Configuration Information

有關群集的所有配置信息都保存在配置服務器上的配置數據庫的集合中。該外殼具有多個幫助程序，這些幫助程序以更具可讀性的方式公開此信息。但是，您始終可以直接在配置數據庫中查詢有關集群的元數據。

**警告**
切勿直接連接到配置服務器，因為您不希望偶然更改或刪除配置服務器數據。而是連接到mongos進程並使用config數據庫查看其數據，就像處理其他任何數據庫一樣：
如果您通過mongos處理配置數據（而不是直接連接到配置服務器），則mongos將確保所有配置服務器保持同步，並防止各種危險的操作，例如意外刪除配置數據庫。

通常，您不應直接更改config數據庫中的任何數據（以下各節中有例外說明）。如果您進行了任何更改，通常必須重新啟動所有mongos服務器才能看到其效果。配置數據庫中有幾個集合。本節涵蓋了每個包含的內容以及如何使用它。

## CONFIG.CHANGELOG

“詳細信息”字段提供有關原始文檔的外觀及其拆分內容的信息。

此輸出顯示集合的第一個塊拆分的外觀。 請注意，每個新塊的“ lastmod”的第二個組件均已更新，因此值分別為Timestamp（9，2）和Timestamp（9，3）。

遷移要稍微複雜一些，實際上會創建四個單獨的變更日誌文檔：一個注意到遷移的開始，一個用於“從”分片，一個用於“到”分片，一個用於在遷移完成後發生的提交 。 中間的兩個文檔很有趣，因為它們提供了流程中每個步驟花費了多長時間的細目。 這可以讓您了解是磁盤，網絡還是其他導致遷移瓶頸的因素。


“詳細信息”中列出的每個步驟都是定時的，“ N的stepN”消息顯示了每個步驟花費的時間（以毫秒為單位）。

當“ from”分片從mongos接收到moveChunk命令時，它：

1.檢查命令參數。

2.與配置服務器確認它可以為遷移獲取分佈式鎖。

3.嘗試聯繫“ to”分片。

4.複製數據。 這被稱為並記錄為“關鍵部分”。

5.與“ to”分片和配置服務器協調以確認遷移。

請注意，“ to”和“ from”分片必須緊密通信，從“ 6的第4步”開始：這些分片直接相互通信，並且配置服務器執行遷移。 如果在最後步驟中“發件人”服務器的網絡連接不穩定，則它可能最終處於無法撤消遷移且無法繼續進行遷移的狀態。 在這種情況下，mongod將關閉。



當“ to”分片從“ from”分片接收命令時，它：

1.遷移索引。 如果此分片以前從未保存過遷移集合中的塊，則需要知道對哪些字段進行了索引。 如果這不是該集合中的某個塊第一次被移到該碎片上，那麼這應該是一個禁忌。

2.刪除塊範圍內的任何現有數據。 遷移或還原過程失敗可能會遺留下一些我們不想干擾當前數據的數據。

3.將數據塊中的所有文檔複製到“ to”分片。

4.重放在復製過程中這些文檔所發生的所有操作（在“ to”分片上）。

5.等待“ to”分片將新遷移的數據複製到大多數服務器。

6.通過更改塊的元數據來聲明遷移是否存在於“ to”分片上，從而進行遷移。

## CONFIG.SETTINGS

該集合包含代表當前平衡器設置和塊大小的文檔。 通過更改此集合中的文檔，可以打開或關閉平衡器或更改塊大小。 請注意，您應該始終連接到mongos，而不是直接連接配置服務器，以更改此集合中的值。

# Tracking Network Connections

集群組件之間有很多連接。 本節介紹一些特定於分片的信息（有關網絡的更多信息，請參見第24章）。

## 獲取連接統計信息

命令connPoolStats返回有關從當前數據庫實例到分片群集或副本集的其他成員的打開的傳出連接的信息。

為避免干擾任何正在運行的操作，connPoolStats不進行任何鎖定。 因此，當connPoolStats收集信息時，計數可能會略有變化，從而導致主機和池連接計數之間的細微差異：


1356/5000
在此輸出中：

“ totalAvailable”顯示從當前mongod / mongos實例到分片集群或副本集的其他成員的可用傳出連接總數。

“ totalCreated”報告由當前mongod / mongos實例創建的與分片集群或副本集的其他成員的傳出連接總數。

“ totalInUse”提供從當前mongod / mongos實例到當前使用的分片集群或副本集的其他成員的傳出連接總數。

“ totalRefreshing”顯示從當前mongod / mongos實例到當前正在刷新的分片群集或副本集的其他成員的傳出連接總數。

“ numClientConnections”標識從當前mongod / mongos實例到分片群集或副本集的其他成員的活動和存儲的傳出同步連接數。這些代表由“ totalAvailable”，“ totalCreated”和“ totalInUse”報告的連接的子集。

“ numAScopedConnection”報告從當前mongod / mongos實例到分片集群或副本集的其他成員的活動的和存儲的傳出範圍的同步連接數。這些代表由“ totalAvailable”，“ totalCreated”和“ totalInUse”報告的連接的子集。

“池”顯示按連接池分組的連接統計信息（正在使用/可用/已創建/刷新）。 一個或多個mongos具有兩個不同的傳出連接池家族：

  基於DBClient的池（“寫入路徑”，由“池”文檔中的字段名稱“全局”標識）

  基於NetworkInterfaceTL的池（“讀取路徑”）

“主機”顯示按主機分組的連接統計信息（正在使用/可用/已創建/刷新）。 它報告當前mongod / mongos實例與分片群集或副本集的每個成員之間的連接。

您可能會在connPoolStats的輸出中看到與其他分片的連接。 這些表明分片正在連接到其他分片以遷移數據。 一個分片的主數據庫將直接連接到另一個分片的主數據庫，並“吸取”其數據。

發生遷移時，分片會設置ReplicaSetMonitor（監視副本集運行狀況的進程），以在遷移的另一端跟踪分片的運行狀況。 mongod永遠不會銷毀此監視器，因此您可能會在一個副本集的日誌中看到有關另一副本集成員的消息。 這是完全正常的，對您的應用程序沒有影響。

## Limiting the Number of Connections

當客戶連接到mongos時，mongos將與至少一個碎片建立連接以傳遞客戶的請求。 因此，到mongos的每個客戶端連接都會產生至少一個從mongos到分片的傳出連接。

如果您有許多mongos進程，它們可能創建的連接數超出了分片的處理能力：默認情況下，mongos最多接受65,536個連接（與mongod相同），因此，如果您有5個mongos進程，每個進程具有10,000個客戶端連接，則它們可能 嘗試創建50,000個與分片的連接！

為了防止這種情況，您可以在mongos的命令行配置中使用--maxConns選項來限制它可以創建的連接數。 以下公式可用於計算分片可從單個mongos處理的最大連接數：

分解此公式的各個部分：

maxConnsPrimary

主數據庫上的最大連接數，通常設置為20,000，以避免蒙哥斯族的連接使分片不堪重負。

（numMembersPerReplicaSet×3）

主節點創建到每個輔助節點的連接，每個輔助節點創建到主節點的兩個連接，總共三個連接。

（其他x 3）

其他是可能連接到您的mongods的其他進程的數量，例如監視或備份代理，直接Shell連接（用於管理）或與其他分片的連接以進行遷移。

numMongosProcesses

分片群集中的mongo總數。請注意，--maxConns僅阻止mongos創建多個連接。達到此限制後，它並沒有什麼特別有用的作用：它只會阻止請求，等待連接“釋放”。因此，必須防止應用程序使用這麼多的連接，尤其是隨著mongos進程數量的增加。

當MongoDB實例乾淨退出時，它將在停止之前關閉所有連接。連接到它的成員將立即在這些連接上收到套接字錯誤，並能夠刷新它們。但是，如果MongoDB實例由於斷電，崩潰或網絡問題而突然脫機，則可能無法完全關閉其所有套接字。在這種情況下，群集中的其他服務器可能會感覺到它們的連接狀況良好，直到嘗試對其執行操作為止。到那時，他們將得到一個錯誤並刷新連接（如果該成員此時再次啟動）。

當只有幾個連接時，這是一個快速的過程。但是，當成千上萬的連接必須一一刷新時，您會遇到很多錯誤，因為必須嘗試嘗試與斷開的每個連接建立連接，並確定它們是不好的。除了重新啟動在重新連接風暴中陷入困境的進程之外，沒有一種特別好的方法來防止這種情況。

# Server Administration

隨著群集的增長，您需要增加容量或更改配置。 本節介紹如何在群集中添加和刪除服務器。

## 添加服務器

您可以隨時添加新的mongos進程。 確保其-configdb選項指定了正確的配置服務器集，並且它們應該立即可供客戶端連接。 要添加新的碎片，請使用第15章中所示的addShard命令。

## 在分片中更改服務器

在使用分片群集時，可能需要更改單個分片中的服務器。 要更改分片的成員身份，請直接連接到分片的主數據庫（而不是通過mongos），然後發出副本集重新配置。 集群配置將獲取更改並自動更新config.shards。 請勿手動修改config.shards。

唯一的例外是，如果您使用獨立服務器作為分片而不是副本集來啟動群集。

### 將存儲庫從標準服務器更改為副本集

最簡單的方法是添加一個新的空副本集碎片，然後刪除獨立的服務器碎片（在下一節中討論）。 遷移將負責將您的數據移至新的分片。

## Removing a Shard

通常，不應從集群中刪除分片。 如果您定期添加和刪除分片，則會給系統帶來不必要的壓力。 如果添加的碎片過多，最好讓系統擴展到其中，而不要刪除它們並稍後再添加。 但是，如有必要，您可以刪除分片。

首先確保平衡器已打開。 平衡器將負責將要刪除的分片上的所有數據移動到其他分片中，該過程稱為“排空”。 要開始排水，請運行removeShard命令。 removeShard會使用分片的名稱，並將該分片上的所有塊都排到其他分片上：

如果要移動的塊很多或很大的塊，排水可能會花費很長時間。 如果您有巨型塊（請參閱“巨型塊”），則可能必須臨時增加塊的大小以允許排水來移動它們。

如果要保留移動量的標籤，請再次運行removeShard以提供當前狀態：



您可以根據需要運行removeShard多次。

塊可能必須拆分才能移動，因此您可能會看到在耗盡期間系統中的塊數量增加了。 例如，假設我們有一個具有以下塊分佈的五片集群：

集群現在有60個塊，其中18個來自shard test-rs3（其中有11個是從此開始的，而7個是由排放拆分創建的）。 一旦所有塊都被移動，如果仍然有一些數據庫以被刪除的碎片為主要數據庫，則需要先刪除它們，然後才能刪除碎片。 分片群集中的每個數據庫都有一個主分片。 如果您要刪除的分片也是集群數據庫之一的主數據庫，則removeShard會在“ dbsToMove”字段中列出數據庫。 要完成刪除碎片的操作，必須在從碎片中遷移所有數據之後將數據庫移至新的碎片，或者刪除數據庫並刪除關聯的數據文件。 removeShard的輸出將類似於：


這不是嚴格必要的，但它確認您已完成該過程。 如果沒有以該分片為主要數據庫的數據庫，則所有數據塊都已從該分片遷移後，您將立即收到此響應。

# Balancing Data